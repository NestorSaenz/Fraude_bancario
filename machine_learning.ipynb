{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score, f1_score, roc_auc_score, roc_curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se carga el archivo csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('balanced_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se dividen los datos en conjuntos de entrenamiento y prueba\n",
    "X = df.drop(columns='isFraud')\n",
    "y = df['isFraud']\n",
    "\n",
    "# Se dividen los datos en conjunto de prueba y entrenamiento\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regresión logistica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy del modelo: 0.9001879868737073\n",
      "Precisión del modelo: 0.90308704014136\n"
     ]
    }
   ],
   "source": [
    "# Se crea y entrena el modelo\n",
    "model = LogisticRegression(max_iter=200)\n",
    "model.fit(x_train, y_train)\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "# Se calcula la presición del modelo\n",
    "accuracy_regresion = accuracy_score(y_test, y_pred)\n",
    "precision_regresion = precision_score(y_test, y_pred)\n",
    "recall_regresion = recall_score(y_test, y_pred)\n",
    "f1_score_regresion = f1_score(y_test, y_pred)\n",
    "auc_roc_regresion = roc_auc_score(y_test, y_pred)\n",
    "print(\"Accuracy del modelo:\", accuracy_regresion)\n",
    "print(\"Precisión del modelo:\", precision_regresion)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Arboles de decisión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Se crea el modelo y se entrena\n",
    "model = DecisionTreeClassifier(max_depth=7, min_samples_split= 300, min_samples_leaf=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy del modelo: 0.925392026405598\n",
      "Precisión del modelo: 0.935700436072132\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "# Predicciones\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "# Calcular la precisión del modelo\n",
    "accuracy_arbol = accuracy_score(y_test, y_pred)\n",
    "precision_arbol = precision_score(y_test, y_pred)\n",
    "recall_arbol = recall_score(y_test, y_pred)\n",
    "f1_score_arbol = f1_score(y_test, y_pred)\n",
    "auc_roc_arbol = roc_auc_score(y_test, y_pred)\n",
    "print(\"Accuracy del modelo:\", accuracy_arbol)\n",
    "print(\"Precisión del modelo:\", precision_arbol)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy del modelo: 0.986533527513573\n",
      "Precisión del modelo: 0.9793000332847857\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# Se inicializa y entrena el modelo\n",
    "model = RandomForestClassifier(max_depth=30, n_estimators=12, random_state=42)\n",
    "model.fit(x_train, y_train)\n",
    "y_pred = model.predict(x_test)\n",
    "accuracy_random_forest = accuracy_score(y_test, y_pred)\n",
    "precision_random_forest = precision_score(y_test, y_pred)\n",
    "recall_random_forest= recall_score(y_test, y_pred)\n",
    "f1_score_random_forest = f1_score(y_test, y_pred)\n",
    "auc_roc_random_forest = roc_auc_score(y_test, y_pred)\n",
    "print(\"Accuracy del modelo:\", accuracy_random_forest)\n",
    "print(\"Precisión del modelo:\", precision_random_forest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 0 ... 1 1 1]\n",
      "Accuracy del modelo: 0.7327157272332322\n",
      "Precisión del modelo: 0.5904132546301288\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# se instacia el modelo\n",
    "model = GaussianNB()\n",
    "\n",
    "# se etrena el modelo\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "# realizamos predicciones sobre el conjunto de prueba\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "# calcular la precisión del modelo\n",
    "accuracy_naive = accuracy_score(y_test, y_pred)\n",
    "precision_naive = precision_score(y_test, y_pred)\n",
    "recall_naive = recall_score(y_test, y_pred)\n",
    "f1_score_naive = f1_score(y_test, y_pred)\n",
    "auc_roc_naive = roc_auc_score(y_test, y_pred)\n",
    "print(y_pred)\n",
    "print(\"Accuracy del modelo:\", accuracy_naive)\n",
    "print(\"Precisión del modelo:\", precision_naive)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos una lista para guardar cada metrica  de cada modelo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "nombre_modelo = ['Regresión Logistica', 'Arból de Decisión', 'Random Forest', 'Naive Bayes']\n",
    "accuracy = [accuracy_regresion, accuracy_arbol, accuracy_random_forest, accuracy_naive]\n",
    "precision = [precision_regresion, precision_arbol, precision_random_forest, precision_naive]\n",
    "recall = [recall_regresion, recall_arbol, recall_random_forest, recall_naive]\n",
    "f1Score = [f1_score_regresion, f1_score_arbol, f1_score_random_forest, f1_score_naive]\n",
    "auc_roc = [auc_roc_regresion, auc_roc_arbol, auc_roc_random_forest, auc_roc_naive]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Guardamos en un diccionario las listas anteriores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultados = {\n",
    "    'Nombre_modelo':nombre_modelo,\n",
    "    'Accuracy': accuracy,\n",
    "    'Precision':precision,\n",
    "    'Recall': recall,\n",
    "    'F1-score': f1Score,\n",
    "    'AUC_ROC': auc_roc\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se crea un DataFrame a partir del diccionario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>AUC_ROC</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nombre_modelo</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Regresión Logistica</th>\n",
       "      <td>0.900188</td>\n",
       "      <td>0.903087</td>\n",
       "      <td>0.830012</td>\n",
       "      <td>0.865009</td>\n",
       "      <td>0.887092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Arból de Decisión</th>\n",
       "      <td>0.925392</td>\n",
       "      <td>0.935700</td>\n",
       "      <td>0.865857</td>\n",
       "      <td>0.899425</td>\n",
       "      <td>0.914282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>0.986534</td>\n",
       "      <td>0.979300</td>\n",
       "      <td>0.985887</td>\n",
       "      <td>0.982583</td>\n",
       "      <td>0.986413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Naive Bayes</th>\n",
       "      <td>0.732716</td>\n",
       "      <td>0.590413</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.742465</td>\n",
       "      <td>0.782594</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Accuracy  Precision    Recall  F1-score   AUC_ROC\n",
       "Nombre_modelo                                                         \n",
       "Regresión Logistica  0.900188   0.903087  0.830012  0.865009  0.887092\n",
       "Arból de Decisión    0.925392   0.935700  0.865857  0.899425  0.914282\n",
       "Random Forest        0.986534   0.979300  0.985887  0.982583  0.986413\n",
       "Naive Bayes          0.732716   0.590413  1.000000  0.742465  0.782594"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_metricas = pd.DataFrame(resultados).set_index('Nombre_modelo')\n",
    "df_metricas"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
